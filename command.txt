conda create -n expose pip python=3.7

conda install pytorch torchvision cudatoolkit=10.2 -c pytorch

pip install -r requirements.txt

https://expose.is.tue.mpg.de/
https://smpl-x.is.tue.mpg.de/
Model DL

python demo.py --image-folder samples --exp-cfg data/conf.yaml --show=False --output-folder output --save-params True --save-vis False --save-mesh False


python demo2.py --video-path "C:/MMD/expose_mmd/samples/45seconds_452-652.mp4" --exp-cfg data/conf.yaml --show=False --output-folder output --save-params True --save-vis True --save-mesh True


python inference.py --exp-cfg data/conf.yaml --datasets openpose --exp-opts datasets.body.batch_size 48 datasets.body.openpose.data_folder samples/images --show=False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --video-path "C:/MMD/expose_mmd/samples/input_100-110.mp4" --exp-cfg data/conf.yaml --show=False --output-folder output --save-params True --save-vis True --save-mesh False --degrees 90


python demo2.py --video-path samples/default.avi --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --video-path samples/cat_30fps_2807-2907.mp4 --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --video-path samples/cat_30fps_512-1200.mp4 --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --video-path samples/magic_doi_7877-9260.mp4 --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False --video-path samples/cat_30fps_512-1200.mp4

python demo2.py --video-path samples/magic_3250-3930.mp4 --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --video-path samples/girl/girl_45132.mp4 --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

python demo2.py --video-path samples/girl2/girl_46949.mp4 --exp-cfg data/conf.yaml --show False --output-folder output --save-params True --save-vis True --save-mesh False

-----------
for MMD
pip install cython
pip install numpy-quaternion
pip install bezier

-------------
for 顔検知

(expose) c:\MMD\expose_mmd>pip install dlib
(expose) c:\MMD\expose_mmd>pip install imutils

python face.py --video-path samples/girl2/girl2_30fps.avi --verbose 10


---------
for lighttrack

pip install tensorflow-gpu==1.15
pip install cython opencv-python pillow matplotlib

(expose) c:\MMD\lighttrack_mmd\lib>python setup_windows.py build_ext --inplace

(expose) c:\MMD\lighttrack_mmd\lib>python setup_cuda.py build_ext --inplace
※ファイル指定は cuのみでOK

(expose) c:\MMD\lighttrack_mmd\graph\torchlight>python setup.py install

pip install setproctitle





右端のtvfilter

if明度調節→ifコントラスト→シャープネス→ダストアンドスクラッチ
が一番よっさそ


グレスケで　全体再生のうちの　2/4　3/4　の位置をグレスケで取得する
双方を比較して　数値がさほど変化がなければカメラが固定なので　自動調整有効にする

グレスケ処理して　ヒストグラム取得　カーブの傾向でどうするか決めるってのが
ちょっと　ヒストグラムの取得周りが謎だけど　一番妥当な解決策ﾄｵﾓﾜﾚﾙ



